---
title: "Rome_Analysis_0"
author: "Barbara Innamorato 213907"
output: html_document
---
```{r}
sessionInfo()
#R version 4.0.5 (2021-03-31)
#Platform: x86_64-apple-darwin17.0 (64-bit)
#Running under: macOS Big Sur 10.16
```


# INTRODUCTION
For this part of the project I'm going to use the geopckage created in the python script. 

I'm going to see if there exist a spatial autocorrelation between the 53 (4 missed) neighborhoods of Rome since "objects closed in space are more related with respect to far objects". This means that maybe the median price previously computed  may depend on some relation between neighborhoods (or not) hence violing the assumption of independce. Spatial data require to use the **Spatial regression approach** in order to take in account the spatial dependence within spatial units and to quantify and test the spatial spillovers. If the linear model is applied the cross relation (spatial spillover) is zero and this leds to misleading results for both estimates and inferences. \

Variables in the dataset are: 

  * "neighbourhood"    : name  
  * "tot_schools"      : total number of schools 
  * "median_price"     
  * "population"        
  * "area"             
  * "pop_density"      : population density
  * "tourist_activites": total number of tourist activities

Fortunately the dataset accounts for 53 neighborhoods so we may be in the position to have signficant results. 

```{r libraries, include=FALSE, warning=FALSE, message=FALSE}
#the package needed
#install.packages("knitr")
#install.packages("leaps")
#install.packages("spdep")
#install.packages("rgdal")
#install.packages("boot")


library(knitr)
library(leaps)
library(spdep)
library(rgdal)
library(boot)
```
Read the file made on the python notebook \
```{r read gpkg, warning=FALSE}
rome <- readOGR(dsn ="rome_analysis.gpkg" , layer = "neighbourhood" )
dim(rome@data)
```
```{r plot rome, fig.align='center'}
plot(rome)
title(main="Rome")
```


```{r explore rome}
print(names(rome@data))
str(rome@data)
head(rome@data)

```
\ 
It is necessary to correct the format of $ tot_schools and tourist_activities from character to numeric:\
```{r}
rome$tot_schools <- as.numeric(rome$tot_schools)
rome$tourist_activites <- as.numeric(rome$tourist_activites)

str(rome@data)
```


Compute centroids \
```{r  centroids, fig.align='center' }
coords <- coordinates(rome) #Defining spatial neighbours
plot(rome, border="blue") ;points(coords, cex=0.8)
title(main="Centroids of Rome neighbours")
#coords
```
\
Check for outliers in the variable price  \
```{r outlier detection, fig.align='center'}
boxplot(rome$median_price) # There are no outlier
median(rome$median_price)
mean(rome$median_price)
```
  + no outlier
  + median price is 65€ (in the notebook it was 68€ for all available rooms. This difference is due to the fact that here there are 4 neighborhoods less than those in the jupyter notebook. Again, this depends on the spatial joins performed to create the gpkg)
  + mean price is 68€ (in the notebook this was around 107€)

# SPATIAL WEIGHT MATRIX 
To take in account the spatial dependce it is necessary to specify a **Spatial weight matrix W** that contains the weighted relation between spatial units. The spatial weight matrix can be defined in different ways, here the k-nearest neighbours, the critical cut-off neighbourhood and the contiguity based method are applied to define these different matrices. This is an important step since the results of the analysis heavily depend on this definition.  \

## DEFINE CLOSENESS - SPATIAL TOPOLOGY
The spatial topology is not natural given so that it is important to choose a criterion in order to define two uniths as neighbors. Since we have the centroids of neighborhoods we can use the distances in the spatial weight matrix, so the first step will be to choose a proper distance.

### K-NEAREST NEIGHBOURS
### With k = 1 and k = 4
To ensure that each unit has the same number of neighbors we use the k-nearest neighbours criterion that implies that two spatial units can be considered as neighbours if their distance is less than or equal to the minimum possible distance that can be found among all the observations. 

Since we want first that all units have at least 1 neighbor, we specify k=1. Then, k=4 to see if there is a (significant) difference. \

```{r knn(s), fig.align='center'}
#k = 1
knn1 <- knn2nb(knearneigh(coords,k=1,longlat=T)) # knearneigh(se longlat = FALSE uso la dist euclidea. in questo caso noi abbiamo point in the form LONG, LAT quindi uso longlat = TRUE)
print(knn1)
plot(rome, border="grey");plot(knn1, coords, add=TRUE)
title(main="k neares neighbor, k = 1")

#k = 4
knn4 <- knn2nb(knearneigh(coords,k=4,longlat=T))
print(knn4)
plot(rome, border="grey");plot(knn4, coords, add=TRUE)
title(main="k neares neighbor, k = 4") 
```
\
- With k = 1 we ask that each neighbor has at least 1 neighbor. \
- With k = 4 now also Ostia is connected to other neighbors. \

### CRITICAL CUT OFF
The Critical cut-off criterion implies that two spatial units can be considered as neighbours if their distance is equal to or less than a certain fixed distance which represents a critical cut-off. The cut off has to be chosen carefully to ensures that each spatial unit has at least one neighbour. Differently from knn, with critical cut off spatial units may have a different number of neighborhoods. \

First compute the minimum distance: \
```{r minimum distance}
knn1 <- knn2nb(knearneigh(coords,k=1,longlat=T))
all.linkedT <- max(unlist(nbdists(knn1, coords, longlat=T)))  # è il cut off massimo che posso usare
all.linkedT # se uso un cutoff minore ho regioni senza vicini
#per trovare il min value del cut off da usare calcolo le distanze con knn e poi prendo il massimo di queste
# --> assicura che ogni regione ha almeno un vicino
```
The minimum distance is 3.124075 kms.
Then, if we use the minimum distance as a cut off we have a neighbor with no links. This could happen if the cut-off is too small.
```{r cut off 0}
dnb <- dnearneigh(coords, 0, 3.124075, longlat=TRUE) # range (0,3.124075) kilometri, uso circle distance
dnb
```


```{r cut off 0 plot, fig.align='center'}
plot(rome, border="grey",xlab="",ylab="",xlim=NULL)
title(main="d nearest neighbours, d = 3.12 km") 
plot(dnb, coords, add=TRUE, col="blue")
```
\
Try with a different cut off (a greater one): \
```{r cut off 1, fig.align='center'}
dnb2 <- dnearneigh(coords, 0, 4.8, longlat=TRUE)
plot(rome, border="grey",xlab="",ylab="",xlim=NULL)
title(main="d nearest neighbours, d = 4.8 km") 
plot(dnb2, coords, add=TRUE, col="red")
dnb2
```

Now all neighborhoods have at least one neighborhood. \
Clearly, as the cut-off distance increases the number of links increases. \
```{r cut off 1 plot, fig.align='center'}
dnb3 <- dnearneigh(coords, 0, 6.0, longlat=TRUE); dnb3
plot(rome, border="grey",xlab="",ylab="",xlim=NULL)
title(main="d nearest neighbours, d = 6.0 km") 
plot(dnb3, coords, add=TRUE, col="blue")
dnb3
```


### CONTIGUITY BASED
The contiguity-based neighbourhood criterion assumes that two spatial units are neighbours if they share a common boundary (or common vertex). Using the queen method borders and verteces are considered. 
```{r cont based}
contnb <- poly2nb(rome, queen=T) #queen = T means "Common border and corner points of the spatial unit"
plot(rome, border="grey");plot(contnb, coords, add=TRUE)
title(main="contiguity based - queen") 
contnb
# sicilia e sardegna sono isolate ovviamente perchè non hanno nessun lato in comnue con altre
# regioni --> se ho delle isole devo usare uno dei due metodi precedenti ma non il contiguity based method. Oppure devo definire
# dei criteri per "forzare" le isole  ad avere dei vicini (ex con i ponti)
```
\
With the queen method the average number of links is 4. Obviously, Ostia is not connected with other neighborhoods since there is no a common boundary nor vertex (miss Agro Romano). For this reason it should be better to consider one of the two other methods.\

## DEFINE SPATIAL WEIGHT MATRIX
Now, it is possible to build the row-standardized spatial weight matrices with all the specification, for the critical cut off the chosen one is dnb2 with a value of 4.8 km. 
```{r row standardized}
sp_knn1 <- nb2listw(knn1,style = 'W') # k=1
sp_knn4 <- nb2listw(knn4,style = 'W') # k=4
sp_dnb2 <- nb2listw(dnb2,style = 'W') # cut off = 4.8
sp_contb <- nb2listw(contnb,style = 'W') # contiguity based queen=T
```

## The MORAN'S I TESTs of spatial autocorrelation 
Now using the moran.test() function I'm going to see if there is a (significant) spatial autocorrelation.\

The quartile distribution of prices could get some hints on the presence of spatial autocorrelation: if neighbors close each other have a similar color, then there could be a positive spatial autocorrelation.

```{r plot quartile, fig.align='center'}
brks <- round(quantile(rome$median_price), digits=3)
colours <- grey((length(brks):2)/length(brks))
plot(rome, col=colours[findInterval(rome$median_price, brks, all.inside=TRUE)])
title(main="Median price for each neighborhood")
```
\
It seems that there is autocorrelation between almost all neighborhoods except those in the and North-East of Rome.

\
Then, a test on the variable "median_price" is performed to see if it is spatially auto-correlated. I am going to do that with each of the Spatial weight matrices previously computed. All of them are tested under the assumption of normality, randomization and with the Monte Carlo test.

### Moran's I with knn
  + k = 1
```{r knn1 moran}
moran.test(rome$median_price, sp_knn1, randomisation=F) #normality
moran.test(rome$median_price, sp_knn1, randomisation=T) #randomization
moran.mc(rome$median_price, sp_knn1, nsim=999) #monte carlo
```

  + k = 4
```{r knn4 moran}
moran.test(rome$median_price, sp_knn4, randomisation=F) #p-value low
moran.test(rome$median_price, sp_knn4, randomisation=T) #p-value low
moran.mc(rome$median_price, sp_knn4, nsim=999) #p-value low
```
\
With knn=1 and knn=4 the Moran's I index is positive in both cases (and with the 3 specifications) with a value of the index around 0.8 and significant p-values that allow to reject the null hypothesis of no spatial autocorrelation. k = 4 seems to perform better\

### Moran's I with critical cut off
```{r cut off moran test}
moran.test(rome$median_price, sp_dnb2, randomisation=F) 
moran.test(rome$median_price, sp_dnb2, randomisation=T) 
moran.mc(rome$median_price, sp_dnb2, nsim=999) 
```
\
Using 4.8 kms as a cut off the Moran's I index is always positive with a value of 0.33 and all the p-values are significant.\


### Moran's I with contiguity based
```{r contiguity based moran test}
moran.test(rome$median_price, sp_contb, randomisation=F) 
moran.test(rome$median_price, sp_contb, randomisation=T) 
moran.mc(rome$median_price, sp_contb, nsim=999) 
```
\
Also with the contiguity based method the p-values are significant and the Moran's I index is positive with a value around 0.73.

  + All the p-values are small enough to reject the null hypothesis of no spatial autocorrelation suggesting that there is a positive spatial autocorrelation. The value of the Moran's I is quite high in all results.

  + The highest value of the Moran's I index is the one obtained with the k-nearest-neighbour with k = 1 (0.87): there may be well defined cluster (better assessed later with the local analysis).


## GLOBAL PRICE SPATIAL AUTOCORRELATION
The Moran's I can be used to detect the presence  of spatial autocorrelation in the residuals of a linear regression model that is we can use it to better check the presence of autocorrelation.

It could be useful to perform a subset selection of the variables to have a first understing of their "potential" meaning and utility.
```{r}
library(leaps)
subset_sel <- regsubsets(median_price ~tot_schools + population +  area + pop_density + tourist_activites, rome)
summary(subset_sel)
```
\
Through the subset selection. \
  * best one-variable model --> area \
  * best two-variables model --> tot_schools + area \
  * best three-variables model --> tot_schools + area + pop_density \
  * best four-variables model --> population + area + pop_density + tourist_activites \
  
Choose the proper number of variables:
```{r choosing number of variables, fig.align='center'}
par(mfrow = c(2,2))
plot(summary(subset_sel)$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(summary(subset_sel)$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")

adj_r2_max = which.max(summary(subset_sel)$adjr2) # identify the location of the maximum point of a vector
points(adj_r2_max, summary(subset_sel)$adjr2[adj_r2_max], col ="red", cex = 2, pch = 20)

# For C_p and BIC, this time looking for the models with the SMALLEST statistic
plot(summary(subset_sel)$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
cp_min = which.min(summary(subset_sel)$cp) 
points(cp_min, summary(subset_sel)$cp[cp_min], col = "red", cex = 2, pch = 20)

plot(summary(subset_sel)$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
bic_min = which.min(summary(subset_sel)$bic) 
points(bic_min, summary(subset_sel)$bic[bic_min], col = "red", cex = 2, pch = 20)
```
\
For RSS, BIC, Cp the best model is the **two-variable** model. Instead, the Adjusted R-Squared suggest that the best one is the four-variables model. However, there is not a big difference in the Adjusted R-Squared from 2 to 4 varibales, so it would be reasonable to choose the model with two variables (reduce complexity). For completeness, I'm going to compare the models with 2 and 4 predictors (just to see if and how "tourist_activities" affect the price).
  
\
The Moran's I test of spatial autocorrelation in OLS residuals is applied to the model with two and four predictors:

```{r lin regr}
lm2 <- lm(median_price ~ tot_schools + area, rome)
lm4 <- lm(median_price ~ population + area + pop_density + tourist_activites, rome)
summary((lm2))
```
```{r sum_lm4}
summary(lm4)
```

\

  
  + the p-values are very low hence being significant;
  + F statistics allow to reject the null hypothesis of no autocorrelation in both models;
  + the value of the Adjusted R-squared increases as the number of variables increase. The fitting is quite good in both models;
  + the significance of the estimates changes with the specifications;
  + it is interesting to note that all varibles have a negative significant coefficient except tourist_activities being the only one positive coefficient even if not in a significant way.
  
  
However, since we just said that there is evidence of spatial autocorrelation, these estimates are not reliable since the assumption of independence is violated. It is possible to use the Moran's I index to check if the OLS residuals are autocorrelated --> application for models lm2, lm4.


Looking at the plot we get a hint about the presence of spatial dependence in the residuals:\
```{r, fig.align='center'}
studres2 <- rstudent(lm2)
studres4 <- rstudent(lm4)
```


```{r plot res, fig.align='center'}
par(mfrow=c(1,2))

resdistr2 <- quantile(studres2) 
colours <- grey((length(resdistr2):2)/length(resdistr2))
plot(rome, col=colours[findInterval(studres2, resdistr2, all.inside=TRUE)])
title(main="Two predictors")

resdistr4 <- quantile(studres4) 
colours <- grey((length(resdistr4):2)/length(resdistr4))
plot(rome, col=colours[findInterval(studres4, resdistr4, all.inside=TRUE)])
title(main="Four predictors")
```

  + With two predictors the two neighbors of Ostia seem to be autocorrelated in a stronger way (darker color) with respect to the four predictors. 
  + There is a small difference for one unit in the southwest of Rome.
  + Overall, differences are not so pronounced. 

\
To apply the Moran's I on OLS the function to be used is lm.morantest(). We previously said that since there are no data about the Agro Romano (that should connect Ostia with the rest of Rome) it should be better to consider the knn and the critical cut-off methods only. 
For knn, I decide to consider only k=4 since it has a smaller p-value than k=1. 

  + two-predictors
```{r lm2 and knn4}
library(spdep)
lm.morantest(lm2, sp_knn4, resfun = rstudent) # low p-value 5.752e-05 (0.000158)

```


```{r lm2 and critical cut off }
lm.morantest(lm2, sp_dnb2, resfun = rstudent) # low p-value

```
\

  + four-predictors
```{r lm4 and knn4}
lm.morantest(lm4, sp_knn4, resfun = rstudent) # low p-value 1.904e-07 (0.011)

```


```{r lm4 and critical cut off }
lm.morantest(lm4, sp_dnb2, resfun = rstudent) # low p-value  

```

All the p-values allow to reject the hypothesis of no autocorrelation between residuals and the strongest evidence comes from the test considering lm2 and k=4. Moreover, this is a robust result since it does not depend on the specification of the spatial weight matrix.\

To apply the test under permutation bootstrap the lm2 and knn4 are chosen:
```{r  test under permutation bootstrap}
library(boot)
LinearSolow.lmx <- lm(median_price ~ population + area + pop_density + tourist_activites, data = rome, x=TRUE)
MoraneI.boot <- function(var, i, ...) {
  var <- var[i]
  lmres <- lm(var ~ LinearSolow.lmx$x - 1)
  return(moran(x=residuals(lmres), ...)$I)	  
}
boot1 <- boot(residuals(LinearSolow.lmx),statistic=MoraneI.boot,  
                R=999, sim="permutation", listw=sp_knn1,  
                n=length(sp_knn1$neighbours), S0=Szero(sp_knn4))
ti <- (boot1$t0 - mean(boot1$t))/sqrt(var(boot1$t))  
boot1
```


```{r plot boot, fig.align='center'}
plot(boot1)
```
\

The dashed line represents the Moran's I and it is on the tail of the distribution, residuals are well approximated by the normal distribution--> enough evidence to **reject the Null Hypothesis of no spatial autocorrelation** .\

Up to now, with two predictors and k-nearest-neighbors with k=4 we have that two most affecting variables for the spatial autocorrelation are **tot_schools** and **area**. 


## LOCAL PRICE SPATIAL AUTOCORRELATION
To investigate the spatial autocorrelation at a **local** level it is possible to use the *moran scatterplot* and the  *local Moran's I*.\

Through the moran scatterplot it is possible to assess which spatial unit contributes more to the presence of autocorrelation but does not provide the statistical significance of the results. 

```{r moran scatterplot}
mplotknn <- moran.plot(rome$median_price, listw=sp_knn4, main="Moran scatterplot with KNN",return_df=F)
grid()
# x: median_price
# y: spatial lag
```
\
The quadrants that give some hints about positiv/negative spatial autocorrelation are:
  + HH quadrant: identifies spatial units with values x and Wx above the average
  + LL quadrant: identifies spatial units with values x and Wx under the average

The units that most affect the spatial autocorrelation are those signed with a black diamond. The slope of the regression line represents the Moran's I and, as we found before, the slope and hence the spatial autocorrelation is positive. This plot allows to identify units that contribute more to the slope of the line and hence units that may be considered as a spatial cluster. \

The significance of the results get with the moran scatterplot can be assessed by the local Moran's I. First, let's identify the influential regions:
```{r hotspost}
hotspot <- as.numeric(row.names(as.data.frame(summary(mplotknn)))) # numeri delle regioni più influenti
```

and we get the numbers of most influential neighborhoods. Values of the spatial lag can be obtained by the function lag.listw(), then it is possible to assign each influential neighbors to the proper Moran scatterplot quadrant:
```{r}
rome$wx <- lag.listw(sp_knn4, rome$median_price) # creats the spatial lag according to the spatial weight matrix

rome$quadrant <- rep("None", length(rome$median_price))
for(i in 1:length(hotspot))  {
  if (rome$median_price[hotspot[i]]>mean(rome$median_price) & rome$wx[hotspot[i]]> mean(rome$wx)) 
        rome$quadrant[hotspot[i]] <- "HH" 
  if (rome$median_price[hotspot[i]]>mean(rome$median_price) & rome$wx[hotspot[i]]< mean(rome$wx)) 
        rome$quadrant[hotspot[i]] <- "HL" 
  if (rome$median_price[hotspot[i]]<mean(rome$median_price) & rome$wx[hotspot[i]]<mean(rome$wx)) 
        rome$quadrant[hotspot[i]] <- "LL" 
  if (rome$median_price[hotspot[i]]<mean(rome$median_price) & rome$wx[hotspot[i]]>mean(rome$wx)) 
        rome$quadrant[hotspot[i]] <- "LH" 
  }
table(rome$quadrant)


```
\
There are 47 eighbours that are not significant for the spatial autocorrelation, the other six are significant in both positive and negative ways. 

And now plot the map of these neighours:
```{r}
rome$colours[rome$quadrant=="None"] <- "white" 
rome$colours[rome$quadrant=="HH"] <- "black" #hotspot regions (spatial cluster)
rome$colours[rome$quadrant=="LL"] <- gray(0.9) 
rome$colours[rome$quadrant=="LH"] <- gray(0.4)
rome$colours[rome$quadrant=="HL"] <- gray(0.7)
plot(rome, col=rome$colours)
legend(x=-10, y=73, legend=c("None", "Low-Low", "High-Low", "Low-High", "High-High"),
                      fill=c("white", gray(0.9), gray(0.7), gray(0.4),
                      "black"), bty="n", cex=0.8)
title(main="Neighbours with influence - knn")
```
\
To assess the significance of the revealed pattern the local Moran's I has to be performed by the localmoran() function:
```{r local moran}
lmI <- localmoran(rome$median_price, sp_knn4) # each obs is a spatial unit and for each we have the moran's I and p-value
head(lmI)
```


Only the first p-value has a low value suggesting the presence of local spatial autocorrelation
```{r distribution of the local Moran}
#The distribution of the local Moran's I index values 
#may be represented graphically typing 
brks <- sort(as.numeric(lmI[,1]))
colours <- grey((0:length(lmI[,1]))/length(lmI[,1]))
plot(rome, col=colours[findInterval(lmI[,1], brks, all.inside=TRUE)])
title(main="Local Moran's I values")
```

Local statistics can be dested trhough the hypothesis of no local autocorrelation, hence providing the significance of spotted pattern got by the Moran scatterplot. 
The p-values map helps: 
```{r}
pval <- as.numeric(lmI[,5])
rome$colpval[pval>0.05] <- "white" 
rome$colpval[pval<=0.05 & pval>0.01] <- gray(0.9) 
rome$colpval[pval<=0.01 & pval>0.001] <- gray(0.7)
rome$colpval[pval<=0.001 & pval>0.0001] <- gray(0.4)
rome$colpval[pval<=0.0001] <- "black"

# più è scuro, più piccolo è il pvalue e quindi più significativa è la spatial dependence
plot(rome, col=rome$colpval)
legend(x=-10, y=73, legend=c("Not significant", 
       "p-value = 0.05", "p-value = 0.01", "p-value = 0.001", 
       "p-value = 0.0001"), fill=c("white", gray(0.9), gray(0.7),    
       gray(0.4), "black"), bty="n", cex=0.8)
title(main="Local Moran's I significance map - KNN")

```

  + significan spatial autocorrelation  in the center of Rome --> well defined cluster
  + significant spatial autocorrelation in North-East --> this is the opposite of the result found above with the global analysis.
  
Hence, it is sure that in the centre of Rome there is spatial autocorrelation.

REMARK: I tried also to perform local analysis with k=1 and with the critical cut-off and results do not change.

# CONCLUSION & RESULTS

From the analysis emerges that there is spatial autocorrelation between neighbors in the center of Rome since all the p-values obtained with the global analysis are significant. Moreover, these results are robust since they do not depend on the Spatial Weight matrix specification. The best performing model in the global analysis is the k-neares-neigbour with k = 4, even if all models always lead to the same result providing the same evidence. \

For further analysis it will be useful to better investigate local phenomena since it appears that there is also a kind of spatial autocorrelation in North-East of Rome that instead, is not captured by the gloabl analysis. 




















